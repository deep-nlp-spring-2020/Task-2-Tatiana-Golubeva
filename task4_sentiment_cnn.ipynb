{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2.4: Text classification via CNN (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you should perform sentiment analysis of the IMDB reviews based on CNN architecture. Read carefully [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1408.5882.pdf) by Yoon Kim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import datasets\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, lower=True, batch_first=True)\n",
    "LABEL = LabelField(batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, tst = datasets.IMDB.splits(TEXT, LABEL)\n",
    "trn, vld = train.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Iterator (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an iterator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    torch.cuda.set_device(2)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = Iterator.splits((trn, vld, tst), \n",
    "                                                  batch_size = 64, \n",
    "                                                  device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN-based text classification model (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, V, D, kernel_sizes, dropout=0.5):\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_filters = 100\n",
    "        self.embedding = nn.Embedding(V, D)\n",
    "\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = self.n_filters, \n",
    "                                              kernel_size = (k, D)) \n",
    "                                    for k in kernel_sizes])\n",
    "        \n",
    "        self.linear = nn.Linear(len(kernel_sizes) * self.n_filters, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x).unsqueeze(1)\n",
    "        cnv = [F.relu(conv(emb)).squeeze(3) for conv in self.convs]  \n",
    "        pool = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in cnv]\n",
    "        cat = self.dropout(torch.cat(pool, dim = 1))\n",
    "        outputs = self.linear(cat)\n",
    "        logit = self.act(outputs)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [3,4,5]\n",
    "vocab_size = len(TEXT.vocab)\n",
    "dropout = 0.5\n",
    "dim = 300\n",
    "\n",
    "model = CNN(vocab_size, dim, kernel_sizes, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(201881, 300)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
       "  )\n",
       "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimization function and the loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think carefully about the stopping criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.010757887881142753, Validation Loss: 0.010054031268755596\n",
      "Epoch: 2, Training Loss: 0.009938647314480372, Validation Loss: 0.009596681984265646\n",
      "Epoch: 3, Training Loss: 0.009675254477773393, Validation Loss: 0.009394608600934346\n",
      "Epoch: 4, Training Loss: 0.009470309250695365, Validation Loss: 0.009289481178919473\n",
      "Epoch: 5, Training Loss: 0.009340208881241934, Validation Loss: 0.009387280861536661\n",
      "Epoch: 6, Training Loss: 0.00919532527582986, Validation Loss: 0.009173213561375937\n",
      "Epoch: 7, Training Loss: 0.009034168810503824, Validation Loss: 0.009045720668633779\n",
      "Epoch: 8, Training Loss: 0.008898489214692797, Validation Loss: 0.009008890684445698\n",
      "Epoch: 9, Training Loss: 0.008820920118263789, Validation Loss: 0.008965045686562857\n",
      "Epoch: 10, Training Loss: 0.008701072846140181, Validation Loss: 0.008954120310147603\n",
      "Epoch: 11, Training Loss: 0.008623659658432007, Validation Loss: 0.00891890817085902\n",
      "Epoch: 12, Training Loss: 0.00853805672952107, Validation Loss: 0.008950007422765097\n",
      "Epoch: 13, Training Loss: 0.008433344694546291, Validation Loss: 0.008885301419099172\n",
      "Epoch: 14, Training Loss: 0.008386357377256666, Validation Loss: 0.00889825956026713\n",
      "Epoch: 15, Training Loss: 0.008342573843683516, Validation Loss: 0.008967312959829965\n",
      "CPU times: user 6min 15s, sys: 2min 48s, total: 9min 4s\n",
      "Wall time: 9min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() \n",
    "    for batch in train_iter:         \n",
    "        \n",
    "        x = batch.text\n",
    "        y = batch.label\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        preds = model(x).squeeze()\n",
    "        loss = loss_func(preds, y.float())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    for batch in val_iter:\n",
    "        \n",
    "        x = batch.text\n",
    "        y = batch.label\n",
    "        \n",
    "        preds = model(x).squeeze()\n",
    "        loss = loss_func(preds, y.float())\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "    val_loss /= len(vld)\n",
    "    \n",
    "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate performance of the trained model (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_iter:\n",
    "    x = batch.text\n",
    "    y = batch.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  tensor([2.4164e-04, 5.3173e-02, 1.0000e+00, 4.3139e-04, 1.9722e-09, 2.3583e-14,\n",
      "        1.1757e-09, 1.0000e+00, 1.0000e+00, 3.4317e-02, 9.9148e-01, 2.4658e-11,\n",
      "        1.1935e-14, 2.4479e-16, 4.3233e-13, 1.0000e+00, 1.8072e-12, 3.1692e-13,\n",
      "        5.8017e-01, 5.8399e-19, 6.4782e-04, 1.0000e+00, 1.0000e+00, 4.2441e-04,\n",
      "        1.0000e+00, 1.0000e+00, 8.0071e-01, 9.5748e-01, 1.2338e-06, 8.4248e-10,\n",
      "        4.6205e-05, 9.9993e-01, 9.4306e-08, 1.0000e+00, 8.9101e-12, 6.0629e-16,\n",
      "        8.6360e-13, 1.0000e+00, 1.0000e+00, 9.9998e-01], device='cuda:2',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "y:  tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1], device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "predictions = model(x).squeeze()\n",
    "print(\"predictions: \", predictions)\n",
    "print(\"y: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9000, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "rounded_preds = torch.round(predictions)\n",
    "correct = (rounded_preds == y.float()).float() \n",
    "accuracy = correct.sum()/len(correct)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1.], device='cuda:2')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8421, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "correct_true_amount =  (correct * y.float()).sum()\n",
    "recall = correct_true_amount / y.float().sum()\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9745, device='cuda:2', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "precision = correct_true_amount / predictions.sum()\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9035, device='cuda:2', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "f1 = 2*precision*recall / (precision + recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the calculated performance\n",
    "\n",
    "### Accuracy: 0.900\n",
    "### Precision: 0.9745\n",
    "### Recall: 0.8421\n",
    "### F1: 0.9035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments (5 points)\n",
    "\n",
    "Experiment with the model and achieve better results. Implement and describe your experiments in details, mention what was helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ?\n",
    "### 2. ?\n",
    "### 3. ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
