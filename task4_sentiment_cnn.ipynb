{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2.4: Text classification via CNN (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you should perform sentiment analysis of the IMDB reviews based on CNN architecture. Read carefully [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1408.5882.pdf) by Yoon Kim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import datasets\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, lower=True, batch_first=True)\n",
    "LABEL = LabelField(batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, tst = datasets.IMDB.splits(TEXT, LABEL)\n",
    "trn, vld = train.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Iterator (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an iterator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    torch.cuda.set_device(3)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = Iterator.splits((trn, vld, tst), \n",
    "                                                  batch_size = 64, \n",
    "                                                  device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN-based text classification model (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, V, D, kernel_sizes, dropout=0.5):\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_filters = 100\n",
    "        self.embedding = nn.Embedding(V, D)\n",
    "\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = self.n_filters, \n",
    "                                              kernel_size = (k, D)) \n",
    "                                    for k in kernel_sizes])\n",
    "        \n",
    "        self.linear = nn.Linear(len(kernel_sizes) * self.n_filters, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x).unsqueeze(1)\n",
    "        cnv = [F.relu(conv(emb)).squeeze(3) for conv in self.convs]  \n",
    "        pool = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in cnv]\n",
    "        cat = self.dropout(torch.cat(pool, dim = 1))\n",
    "        outputs = self.linear(cat)\n",
    "        logit = self.act(outputs)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [3,4,5]\n",
    "vocab_size = len(TEXT.vocab)\n",
    "dropout = 0.5\n",
    "dim = 300\n",
    "\n",
    "model = CNN(vocab_size, dim, kernel_sizes, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(202379, 300)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
       "  )\n",
       "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimization function and the loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think carefully about the stopping criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.010644211176463535, Validation Loss: 0.009809689891338349\n",
      "Epoch: 2, Training Loss: 0.009914062336512975, Validation Loss: 0.00955055730342865\n",
      "Epoch: 3, Training Loss: 0.009621580059187753, Validation Loss: 0.00938572502930959\n",
      "Epoch: 4, Training Loss: 0.00942767163344792, Validation Loss: 0.009257817216714223\n",
      "Epoch: 5, Training Loss: 0.009226666627611433, Validation Loss: 0.009182151993115744\n",
      "Epoch: 6, Training Loss: 0.009088774820736476, Validation Loss: 0.009084957993030548\n",
      "Epoch: 7, Training Loss: 0.008979467001983097, Validation Loss: 0.009051678717136384\n",
      "Epoch: 8, Training Loss: 0.00881090454033443, Validation Loss: 0.008938081240653992\n",
      "Epoch: 9, Training Loss: 0.008730058087621416, Validation Loss: 0.008911931836605071\n",
      "Epoch: 10, Training Loss: 0.00860604135308947, Validation Loss: 0.008885545110702515\n",
      "Epoch: 11, Training Loss: 0.00853726339680808, Validation Loss: 0.008890131962299347\n",
      "Epoch: 12, Training Loss: 0.008464037997382028, Validation Loss: 0.008853386318683624\n",
      "Epoch: 13, Training Loss: 0.00837377861567906, Validation Loss: 0.008841645030180614\n",
      "Epoch: 14, Training Loss: 0.008322778253895895, Validation Loss: 0.008844908237457275\n",
      "Epoch: 15, Training Loss: 0.008265111250536783, Validation Loss: 0.008860306056340535\n",
      "CPU times: user 3min 21s, sys: 1min 17s, total: 4min 39s\n",
      "Wall time: 5min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() \n",
    "    for batch in train_iter:         \n",
    "        \n",
    "        x = batch.text\n",
    "        y = batch.label\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        preds = model(x).squeeze()\n",
    "        loss = loss_func(preds, y.float())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    for batch in val_iter:\n",
    "        \n",
    "        x = batch.text\n",
    "        y = batch.label\n",
    "        \n",
    "        preds = model(x).squeeze()\n",
    "        loss = loss_func(preds, y.float())\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "    val_loss /= len(vld)\n",
    "    \n",
    "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate performance of the trained model (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "for batch in test_iter:\n",
    "    x = batch.text\n",
    "    y = batch.label\n",
    "    predictions = model(x).squeeze()\n",
    "    rounded_preds = torch.round(predictions)\n",
    "    correct = (rounded_preds == y.float()).float() \n",
    "    accuracy = correct.sum()/len(correct)\n",
    "    correct_true_amount =  (correct * y.float()).sum()\n",
    "    recall = correct_true_amount / y.float().sum()\n",
    "    precision = correct_true_amount / predictions.sum()\n",
    "    accuracies.append(accuracy)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eye = [1]\n",
    "for i, r in enumerate(recalls):\n",
    "    if  torch.isnan(r):\n",
    "        recalls[i] = torch.Tensor(eye).cuda().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  tensor(0.8635, device='cuda:3')\n",
      "precision:  tensor(0.8232, device='cuda:3', grad_fn=<MeanBackward0>)\n",
      "recall:  tensor(0.8567, device='cuda:3')\n",
      "f1:  tensor(0.8396, device='cuda:3', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "accuracy = torch.mean(torch.stack(accuracies))\n",
    "print(\"accuracy: \", accuracy)\n",
    "precision = torch.mean(torch.stack(precisions))\n",
    "print(\"precision: \", precision)\n",
    "recall = torch.mean(torch.stack(recalls))\n",
    "print(\"recall: \", recall)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"f1: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the calculated performance\n",
    "\n",
    "### Accuracy: 0.8635\n",
    "### Precision: 0.8232\n",
    "### Recall: 0.8567\n",
    "### F1: 0.8396"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments (5 points)\n",
    "\n",
    "Experiment with the model and achieve better results. Implement and describe your experiments in details, mention what was helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "### dropout = 0.5, change Adam optimizer to SGD momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, V, D, kernel_sizes, dropout=0.3):\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_filters = 100\n",
    "        self.embedding = nn.Embedding(V, D)\n",
    "\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = self.n_filters, \n",
    "                                              kernel_size = (k, D)) \n",
    "                                    for k in kernel_sizes])\n",
    "        \n",
    "        self.linear = nn.Linear(len(kernel_sizes) * self.n_filters, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x).unsqueeze(1)\n",
    "        cnv = [F.relu(conv(emb)).squeeze(3) for conv in self.convs]  \n",
    "        pool = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in cnv]\n",
    "        cat = self.dropout(torch.cat(pool, dim = 1))\n",
    "        outputs = self.linear(cat)\n",
    "        logit = self.act(outputs)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [3,4,5]\n",
    "vocab_size = len(TEXT.vocab)\n",
    "dropout = 0.5\n",
    "dim = 300\n",
    "epochs = 10\n",
    "\n",
    "model = CNN(vocab_size, dim, kernel_sizes, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(201784, 300)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
       "  )\n",
       "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.010855203005245754, Validation Loss: 0.010905149841308593\n",
      "Epoch: 2, Training Loss: 0.010852082306998117, Validation Loss: 0.01090480485757192\n",
      "Epoch: 3, Training Loss: 0.010850114720208304, Validation Loss: 0.01090240683555603\n",
      "Epoch: 4, Training Loss: 0.010846595283917019, Validation Loss: 0.01088865509033203\n",
      "Epoch: 5, Training Loss: 0.010823195392744882, Validation Loss: 0.010823581592241923\n",
      "Epoch: 6, Training Loss: 0.010669763101850237, Validation Loss: 0.010673945093154908\n",
      "Epoch: 7, Training Loss: 0.010468876664979117, Validation Loss: 0.01014719382127126\n",
      "Epoch: 8, Training Loss: 0.010272592316355024, Validation Loss: 0.009920679012934367\n",
      "Epoch: 9, Training Loss: 0.01008944388798305, Validation Loss: 0.009886492236455281\n",
      "Epoch: 10, Training Loss: 0.009969590612820217, Validation Loss: 0.009703847845395406\n",
      "CPU times: user 2min 17s, sys: 50.7 s, total: 3min 8s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() \n",
    "    for batch in train_iter:         \n",
    "        \n",
    "        x = batch.text\n",
    "        y = batch.label\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        preds = model(x).squeeze()\n",
    "        loss = loss_func(preds, y.float())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    for batch in val_iter:\n",
    "        \n",
    "        x = batch.text\n",
    "        y = batch.label\n",
    "        \n",
    "        preds = model(x).squeeze()\n",
    "        loss = loss_func(preds, y.float())\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "    val_loss /= len(vld)\n",
    "    \n",
    "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It works worse than previos model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I have tried to change some other params but the result was terrible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
